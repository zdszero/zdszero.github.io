<!doctype html>
<html >

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />

  <link rel="stylesheet" type="text/css" href="../../WikiTheme/template.css" />

  <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
  <script type='text/javascript' src="../../WikiTheme/menu/js/jquery.cookie.js"></script>
  <script type='text/javascript' src="../../WikiTheme/menu/js/jquery.hoverIntent.minified.js"></script>
  <script type='text/javascript' src="../../WikiTheme/menu/js/jquery.dcjqaccordion.2.7.min.js"></script>
  <script type="text/javascript" src="../../WikiTheme/menu/js/jquery.sticky-kit.js "></script>
  <script type="text/javascript" src="../../WikiTheme/menu/js/sticky_menu.js"></script>

  <link rel="stylesheet" type="text/css" href="../../WikiTheme/menu/css/skins/blue.css"/>
  <link rel="stylesheet" type="text/css" href="../../WikiTheme/menu/css/skins/graphite.css"/>
  <link rel="stylesheet" type="text/css" href="../../WikiTheme/menu/css/skins/grey.css"/>

  <meta name="generator" content="pandoc" />
      <title>
    Activation
  </title>
    <link rel="stylesheet" href="../../WikiTheme/theme/bootstrap.css"  />
        <script
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
        type="text/javascript"></script>
      </head>

<body>
    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">Activation</span>
        <ul class="nav pull-right doc-info">
          <p class="navbar-text">
                                                      </p>
                  </ul>
      </div>
    </div>
  </div>
    <div class="container">
    <div class="row">
            <div id="TOC" class="span3">
        <div class="well toc">
          <ul>
          <li><a href="#relu" id="toc-relu">ReLU</a></li>
          <li><a href="#gelu" id="toc-gelu">GeLU</a></li>
          <li><a href="#silu" id="toc-silu">SiLU</a></li>
          <li><a href="#gated-variants" id="toc-gated-variants">Gated
          Variants</a></li>
          </ul>
        </div>
      </div>
            <div class="span9">
                <p>所以激活函数的作用是
                <strong>打破线性性，引入非线性</strong>，使神经网络可以：</p>
                <ul>
                <li>拟合任意复杂的函数（通用近似能力）</li>
                <li>表达分类边界、抽象特征、决策逻辑等复杂结构</li>
                </ul>
                <h3 id="relu">ReLU</h3>
                <p><span class="math display">\[ \text{FF}(x) =
                \text{ReLU}(xW_1)W_2 \]</span></p>
                <p><span class="math display">\[ \text{ReLU}(x) :=
                \max(0, x) \]</span></p>
                <p><strong>原始 Transformer</strong>
                使用的前馈激活函数就是 ReLU。</p>
                <h3 id="gelu">GeLU</h3>
                <figure>
                <img
                src="../.././WikiImage/image_2025-07-22-12-43-30.png"
                width="500" alt="ReLU, GeLu, SiLU" />
                <figcaption aria-hidden="true">ReLU, GeLu,
                SiLU</figcaption>
                </figure>
                <p><span class="math display">\[FF(x) =
                \mathrm{GELU}(xW_1)W_2\]</span></p>
                <p><span class="math display">\[\mathrm{GELU}(x) := x \,
                \Phi(x)\]</span></p>
                <p>这里的 <span class="math inline">\(\Phi(x)\)</span>
                是
                <strong>标准正态分布的累积分布函数（CDF）</strong>，也叫高斯误差函数的一种形式。</p>
                <p><span class="math display">\[ \Phi(x) :=
                \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi}} e^{-t^2/2} \,
                dt \]</span></p>
                <p>这是一个 S
                形的平滑函数，表示「一个标准正态分布随机变量小于等于
                <span class="math inline">\(x\)</span> 的概率」。</p>
                <p>GeLU 的直观理解</p>
                <p>GeLU 的激活函数可以理解为：对每个输入 <span
                class="math inline">\(x\)</span>，按概率 <span
                class="math inline">\(\Phi(x)\)</span>
                <strong>部分保留它的值</strong>。</p>
                <ul>
                <li><span class="math inline">\(x &lt; 0\)</span>
                时，<span class="math inline">\(\Phi(x) &lt;
                0.5\)</span>，输出被削弱；</li>
                <li><span class="math inline">\(x &gt; 0\)</span>
                时，<span class="math inline">\(\Phi(x) &gt;
                0.5\)</span>，输出更接近 <span
                class="math inline">\(x\)</span>；</li>
                <li>整体是一种 <strong>平滑的门控机制</strong>。</li>
                </ul>
                <p><strong>常用近似（用于实际计算）：</strong></p>
                <p>为了加速计算，GeLU 经常使用以下近似形式：</p>
                <p><span class="math display">\[
                \mathrm{GeLU}(x) \approx 0.5 x \left(1 +
                \tanh\left[\sqrt{\frac{2}{\pi}} \left(x +
                0.044715x^3\right)\right]\right)
                \]</span></p>
                <p>这个近似非常精确，且可快速计算，广泛用于 BERT、GPT
                等模型。</p>
                <p>GPT 1/2/3</p>
                <h3 id="silu">SiLU</h3>
                <p><span class="math display">\[\text{FF}(x) =
                \text{SiLU}(xW_1)W_2\]</span></p>
                <p><span class="math display">\[\text{SiLU}(x) = x \cdot
                \sigma(x) = \frac{x}{1 + e^{-x}}\]</span></p>
                <h3 id="gated-variants">Gated Variants</h3>
                <h4 id="glu">GLU</h4>
                <p>GLUs (Gated Linear Unit) modify the “first part” of a
                FF layer:</p>
                <p><span class="math display">\[FF(x) = \max(0, xW_1)
                W_2\]</span></p>
                <p>Instead of a linear + ReLU, argument the above with
                an (elementwise) linear term</p>
                <p><span class="math display">\[\max(0, xW_1)
                \rightarrow \max(0, xW_1) \otimes (xV)\]</span></p>
                <p>This gives the gated variant (ReGLU) - note that we
                have an extra parameter (V)</p>
                <p><span class="math display">\[FF_{\text{ReGLU}}(x) =
                (\max(0, xW_1) \otimes xV) W_2\]</span></p>
                <h4 id="geglu">GeGLU</h4>
                <p><span class="math display">\[FFN_{\text{GeGLU}}(x, W,
                V, W_2) = (\text{GELU}(xW) \otimes xV)W_2\]</span></p>
                <h4 id="swiglu">SwiGLU</h4>
                <p><span class="math display">\[FFN_{\text{SwiGLU}}(x,
                W, V, W_2) = (\text{Swish}_1(xW) \otimes
                xV)W_2\]</span></p>
              </div>
    </div>
  </div>
</body>

</html>
